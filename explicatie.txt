	Ce am facut: am folosit un autoencoder (o retea neuronala care incearca sa invete o reprezentare compacta a inputului) ca sa incerc sa invat structura datelor fara etichete atasate prin gasirea unei codificari pentru imagine.
	Un articol care explica bine conceptul de autoencoder: https://blog.keras.io/building-autoencoders-in-keras.html
	Dupa antrenarea autoencoder-ului, iau prima parte (cea care se ocupa de codificare, adica toate straturile pana la cel cu numarul cel mai mic de unitati) si folosesc aceasta retea pre-antrenata pentru a construi reteaua care se ocupa de predictie.
	Urmeaza inca o etapa de antrenare folosind reteaua de predictie folosind datele etichetate. Ponderile tuturor straturilor cu exceptia ultimului au ponderile "invatate" pe structura datelor neetichetate, asa ca eroarea la antrenare ar trebui sa scada mai repede decat daca ar fi initializate aleator.
	Dat fiind ca e probabil ca un autoencoder sa invete functia de identitate in cazul in care numarul de unitati din codificare este mai mare decat numarul de unitati din input, intai se corup datele prin adaugarea de zgomot (fie Gaussian, fie prin transformarea semnalului unor unitati in 0, lucru care poate fi simulat prin Dropout). Urmeaza sa invatam autoencoderul sa reconstruiasca inputul prin minimizarea erorii dintre imaginea originala si imaginea obtinuta de decoder pornind de la imaginea corupta.
	Metoda asta poate fi adaptata la orice tip de retea neuronala.
